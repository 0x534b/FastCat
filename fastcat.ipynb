{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "Simply run the below code to train and evaluate on a validation set!\\\n",
    "Parameters you will want to configure:\n",
    "- `PATH`: the path to your training/testing data\n",
    "- `EN_VAL`: enables splitting training data to produce a validation set for evaluation\n",
    "- `EN_TST`: when enabled the model predicts the test data after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from tqdm.autonotebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg():\n",
    "    IMG_SZ = 128\n",
    "    TRG_COLS = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "    PATH = 'C:\\\\data-fast\\\\cs480-kaggle\\\\data\\\\'\n",
    "    N_TRG = len(TRG_COLS)\n",
    "    BATCH_SZ = 32\n",
    "    SEED = None #42\n",
    "    X_SZ = 163\n",
    "    DEVICE = 'cuda'\n",
    "    N_PF = 1000\n",
    "    VAL_SZ = 0.2\n",
    "    EN_VAL = False\n",
    "    EN_TST = True\n",
    "\n",
    "CFG = Cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset(Dataset):\n",
    "    def __init__(self, image_paths, features, labels=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load & augment image\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # load features & labels\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "            return (image, feature), label\n",
    "        else:\n",
    "            return image, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "\n",
    "        # load pre-trained efficientnet without the top classification layers\n",
    "        self.efficientnet = models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
    "        self.efficientnet = nn.Sequential(*list(self.efficientnet.children())[:-2])\n",
    "        \n",
    "        # load pre-trained mobilevit without the top classification layer\n",
    "        model_name = 'mobilevitv2_100'\n",
    "        self.mobilevit = timm.create_model(model_name, pretrained=True)\n",
    "        self.mobilevit = nn.Sequential(*list(self.mobilevit.children())[:-1])\n",
    "\n",
    "        self.img_to_flat = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_input, data_input):\n",
    "        # CNN embedding\n",
    "        x_eff = self.efficientnet(image_input)\n",
    "        x_eff = self.img_to_flat(x_eff)\n",
    "\n",
    "        # ViT embedding\n",
    "        x_mv = self.mobilevit(image_input)\n",
    "        x_mv = self.img_to_flat(x_mv)\n",
    "\n",
    "        output = torch.cat((x_eff, x_mv, data_input), dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_data = pd.read_csv(f'{CFG.PATH}/train.csv')\n",
    "\n",
    "# get aux feature col names\n",
    "prefixes = ['WORLDCLIM_BIO', 'SOIL_', 'MODIS_', 'VOD_']\n",
    "feature_cols = [c for c in train_data.columns if any(c.startswith(prefix) for prefix in prefixes)]\n",
    "\n",
    "train_features = train_data[feature_cols].values\n",
    "train_filenames = train_data['id'].values\n",
    "train_labels = train_data[CFG.TRG_COLS].values\n",
    "train_labels = np.log10(train_labels)\n",
    "\n",
    "if CFG.EN_TST:\n",
    "    test_data = pd.read_csv(f'{CFG.PATH}/test.csv')\n",
    "    test_features = test_data[feature_cols].values\n",
    "    test_filenames = test_data['id'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# augmentation for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.1,\n",
    "        contrast=0.1,\n",
    "        saturation=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_image_paths = [os.path.join(f'{CFG.PATH}/train_images', f'{filename}.jpeg') for filename in train_filenames]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# split out val set\n",
    "if CFG.EN_VAL:\n",
    "    train_image_paths, val_image_paths, train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        train_image_paths, train_features, train_labels, test_size=CFG.VAL_SZ, random_state=42\n",
    "    )\n",
    "\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "train_features = PolynomialFeatures(2).fit_transform(train_features)[:, :CFG.N_PF]\n",
    "train_dataset = RawDataset(train_image_paths, train_features, train_labels, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SZ, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "if CFG.EN_VAL:\n",
    "    val_features = scaler.transform(val_features)\n",
    "    val_features = PolynomialFeatures(2).fit_transform(val_features)[:, :CFG.N_PF]\n",
    "    val_dataset = RawDataset(val_image_paths, val_features, val_labels, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG.BATCH_SZ, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "if CFG.EN_TST:\n",
    "    test_image_paths = [os.path.join(f'{CFG.PATH}/test_images', f'{filename}.jpeg') for filename in test_filenames]\n",
    "    test_features = scaler.transform(test_features)\n",
    "    test_features = PolynomialFeatures(2).fit_transform(test_features)[:, :CFG.N_PF]\n",
    "    test_dataset = RawDataset(test_image_paths, test_features, None, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG.BATCH_SZ, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate embedding model\n",
    "embed_model = EmbeddingModel()\n",
    "embed_model.to(CFG.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train + Validation Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_model.eval()\n",
    "\n",
    "train_features_catboost = []\n",
    "train_labels_catboost = []\n",
    "\n",
    "if CFG.EN_VAL:\n",
    "    val_features_catboost = []\n",
    "    val_labels_catboost = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (image_batch, feature_batch), label_batch in tqdm(train_loader):\n",
    "        image_batch = image_batch.to(CFG.DEVICE)\n",
    "        feature_batch = feature_batch.to(CFG.DEVICE)\n",
    "\n",
    "        # embed\n",
    "        features = embed_model(image_batch, feature_batch)\n",
    "        train_features_catboost.append(features.cpu().numpy())\n",
    "        train_labels_catboost.append(label_batch.cpu().numpy())\n",
    "\n",
    "    if CFG.EN_VAL:\n",
    "        for (image_batch, feature_batch), label_batch in tqdm(val_loader):\n",
    "            image_batch = image_batch.to(CFG.DEVICE)\n",
    "            feature_batch = feature_batch.to(CFG.DEVICE)\n",
    "\n",
    "            # embed\n",
    "            features = embed_model(image_batch, feature_batch)\n",
    "            val_features_catboost.append(features.cpu().numpy())\n",
    "            val_labels_catboost.append(label_batch.cpu().numpy())\n",
    "\n",
    "train_features_catboost = np.concatenate(train_features_catboost, axis=0)\n",
    "train_labels_catboost = np.concatenate(train_labels_catboost, axis=0)\n",
    "np.save(f'{CFG.PATH}/../train_features_catboost', np.array(train_features_catboost))\n",
    "np.save(f'{CFG.PATH}/../train_labels_catboost', np.array(train_labels_catboost))\n",
    "\n",
    "if CFG.EN_VAL:\n",
    "    val_features_catboost = np.concatenate(val_features_catboost, axis=0)\n",
    "    val_labels_catboost = np.concatenate(val_labels_catboost, axis=0)\n",
    "    np.save(f'{CFG.PATH}/../val_features_catboost', np.array(val_features_catboost))\n",
    "    np.save(f'{CFG.PATH}/../val_labels_catboost', np.array(val_labels_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_catboost = np.load(f'{CFG.PATH}/../train_features_catboost.npy')\n",
    "train_labels_catboost = np.load(f'{CFG.PATH}/../train_labels_catboost.npy')\n",
    "\n",
    "if CFG.EN_VAL:\n",
    "    val_features_catboost = np.load(f'{CFG.PATH}/../val_features_catboost.npy')\n",
    "    val_labels_catboost = np.load(f'{CFG.PATH}/../val_labels_catboost.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.EN_TST:\n",
    "    embed_model.eval()\n",
    "\n",
    "    test_features_catboost = []\n",
    "    test_labels_catboost = []\n",
    "\n",
    "    from tqdm.autonotebook import tqdm\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_batch, feature_batch in tqdm(test_loader):\n",
    "            image_batch = image_batch.to(CFG.DEVICE)\n",
    "            feature_batch = feature_batch.to(CFG.DEVICE)\n",
    "\n",
    "            # Extract features\n",
    "            features = embed_model(image_batch, feature_batch)\n",
    "            test_features_catboost.append(features.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    test_features_catboost = np.concatenate(test_features_catboost, axis=0)\n",
    "\n",
    "    np.save(f'{CFG.PATH}/../test_features_catboost', np.array(test_features_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.EN_TST:\n",
    "    test_features_catboost = np.load(f'{CFG.PATH}/../test_features_catboost.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_models = {}\n",
    "scores = {}\n",
    "\n",
    "for i, col in tqdm(enumerate(CFG.TRG_COLS), total=len(CFG.TRG_COLS)):\n",
    "    model = CatBoostRegressor(\n",
    "        depth=6,\n",
    "        learning_rate=0.1,\n",
    "        iterations=1000,\n",
    "        loss_function='RMSE',\n",
    "        verbose=True,\n",
    "        task_type=('GPU' if CFG.DEVICE == 'cuda' else 'CPU'),\n",
    "        random_state=CFG.SEED,\n",
    "    )\n",
    "\n",
    "    if CFG.EN_VAL:\n",
    "        model.fit(train_features_catboost, train_labels_catboost[:, i], verbose=True,\n",
    "                eval_set=(val_features_catboost, val_labels_catboost[:, i]))\n",
    "        \n",
    "        y_curr_val_pred = model.predict(val_features_catboost)\n",
    "        \n",
    "        r2_col = r2_score(val_labels_catboost[:, i], y_curr_val_pred)\n",
    "        scores[col] = r2_col\n",
    "        print(f'Target Trained: {col}, R2: {r2_col:.3f}')\n",
    "    else:\n",
    "        model.fit(train_features_catboost, train_labels_catboost[:, i], verbose=True)\n",
    "        print(f'Target Trained: {col}')\n",
    "\n",
    "    cat_models[col] = model\n",
    "\n",
    "if CFG.EN_VAL:\n",
    "    mean_r2 = np.mean(list(scores.values()))\n",
    "    print(f'Mean R2: {mean_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.EN_TST:\n",
    "    predictions_df = pd.DataFrame()\n",
    "    test_data = pd.read_csv(f'{CFG.PATH}/test.csv')\n",
    "    predictions_df['id'] = test_data['id']\n",
    "\n",
    "    for trait in CFG.TRG_COLS:\n",
    "        model = cat_models[trait]\n",
    "        predictions = model.predict(test_features_catboost)\n",
    "        predictions = np.power(10, predictions)\n",
    "        predictions_df[trait.split('_')[0]] = predictions\n",
    "\n",
    "    predictions_df.to_csv(f'{CFG.PATH}/../submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some R^2 values I've collected on different train/val splits\n",
    "data = [\n",
    "    0.2596423142137745,\n",
    "    0.260868698490226,\n",
    "    0.2574254267340103,\n",
    "    0.2583413629448405,\n",
    "]\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.axhline(y=mean, color='blue', linestyle='-', label=f'Mean $R^2$: {mean:.5f}')\n",
    "plt.axhline(y=mean + std_dev, color='red', linestyle='--', label=f'Std Dev ($\\pm$): $\\pm${std_dev:.5f}')\n",
    "plt.axhline(y=mean - std_dev, color='red', linestyle='--')\n",
    "plt.scatter([0]*len(data), data, marker='o', label='Measured Values')\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.title('Variation of Validation Scores')\n",
    "plt.ylabel('$R^2$ Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs480venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
